# ğŸš€ Quick Start Guide - AutoML Classification System

## âš¡ Get Running in 3 Steps

### Step 1: Install Dependencies
```powershell
pip install -r requirements.txt
```

### Step 2: Run the Application
```powershell
streamlit run app.py
```

### Step 3: Upload Dataset
- Open browser at http://localhost:8501
- Upload `sample_data/sample_dataset.csv` or your own CSV file
- Follow the guided workflow!

## ğŸ“‹ Complete Workflow

1. **ğŸ“ Upload Dataset** â†’ Select CSV file and target column
2. **ğŸ” Run EDA** â†’ Click "Run Automated EDA" button
3. **âš ï¸ Detect Issues** â†’ Click "Detect Data Issues" and approve fixes
4. **âš™ï¸ Preprocess** â†’ Click "Configure Preprocessing" then "Apply Preprocessing"
5. **ğŸ¤– Train Models** â†’ Click "Train All Models" (takes 2-5 minutes)
6. **ğŸ“Š Compare** â†’ View comparison dashboard automatically
7. **ğŸ“„ Generate Report** â†’ Click "Generate Comprehensive Report"

## ğŸ¯ Project Deliverables Checklist

- [ ] **Streamlit Application** - Working and tested locally
- [ ] **GitHub Repository** - Code pushed with all files
- [ ] **Deployment** - App deployed on Streamlit Cloud
- [ ] **Report** (3-5 pages) - PDF document with screenshots
- [ ] **Demo Video** (5 minutes) - Screen recording of app usage
- [ ] **Screenshots** - Saved in `screenshots/` folder

## ğŸ“¦ What's Included

âœ… **7 Classification Models:**
- Logistic Regression
- K-Nearest Neighbors
- Decision Tree
- Naive Bayes
- Random Forest
- Support Vector Machine
- Rule-Based Classifier

âœ… **Complete EDA:**
- Missing values analysis
- Outlier detection (IQR & Z-score)
- Correlation matrix
- Distribution plots
- Categorical analysis

âœ… **Smart Preprocessing:**
- Multiple imputation strategies
- Outlier handling
- Feature scaling
- Encoding (One-Hot & Label)
- Train-test splitting

âœ… **Advanced Features:**
- Hyperparameter optimization (Grid/Random Search)
- Issue detection with user approval
- Comprehensive metrics (Accuracy, Precision, Recall, F1, ROC-AUC)
- Interactive visualizations
- Downloadable reports (Markdown & HTML)

## ğŸŒ Deploy to Streamlit Cloud

```bash
# 1. Initialize git and commit
git init
git add .
git commit -m "AutoML Classification System"

# 2. Push to GitHub
git remote add origin <your-repo-url>
git push -u origin main

# 3. Deploy on Streamlit Cloud
# - Go to https://share.streamlit.io/
# - Connect your GitHub repository
# - Set main file: app.py
# - Click Deploy!
```

## ğŸ¥ Recording Demo Video

**Suggested Flow (5 minutes):**
1. Show main interface (15s)
2. Upload dataset and show basic info (30s)
3. Run EDA and show visualizations (45s)
4. Detect and handle data issues (45s)
5. Configure and apply preprocessing (45s)
6. Train models and show results (90s)
7. Compare models and show dashboard (45s)
8. Generate and download report (30s)

**Tools:** OBS Studio, Loom, or Windows Game Bar

## ğŸ“ Writing the Report

**Structure:**
1. **Introduction** - Project overview and objectives
2. **Methodology** - System design and algorithms
3. **Implementation** - Key features and workflow
4. **Results** - Screenshots and performance metrics
5. **Conclusion** - Achievements and future work

**Include:**
- Screenshots from each module
- Sample results table
- Architecture diagram (optional)
- Code snippets (optional)

## ğŸ› Common Issues & Fixes

**Models training too slow?**
â†’ Use Randomized Search with 10 iterations instead of Grid Search

**Memory error?**
â†’ Reduce dataset size or close other applications

**Import errors?**
â†’ Run: `pip install -r requirements.txt` again

**Port already in use?**
â†’ Run: `streamlit run app.py --server.port 8502`

## ğŸ’¡ Testing Checklist

- [ ] Test with sample dataset (iris data)
- [ ] Test with dataset containing missing values
- [ ] Test with imbalanced dataset
- [ ] Test with purely numerical data
- [ ] Test with mixed numerical/categorical data
- [ ] Test all preprocessing options
- [ ] Test both Grid and Randomized Search
- [ ] Download comparison CSV
- [ ] Download report (Markdown & HTML)

## ğŸ“Š Expected Results (Iris Dataset)

When you test with the included sample dataset, you should see:
- **Best Model**: Random Forest or SVM
- **Expected F1-Score**: 0.90 - 0.97
- **Training Time**: 10-60 seconds total
- **No Data Issues**: Clean dataset, no missing values

## ğŸ† Meeting Project Requirements

| Requirement | File/Module | Status |
|------------|-------------|--------|
| Dataset Upload | `data_loader.py` | âœ… |
| EDA | `eda.py` | âœ… |
| Issue Detection | `issue_detector.py` | âœ… |
| Preprocessing | `preprocessor.py` | âœ… |
| Model Training | `model_trainer.py` | âœ… |
| Hyperparameter Tuning | `model_trainer.py` | âœ… |
| Model Comparison | `model_evaluator.py` | âœ… |
| Report Generation | `report_generator.py` | âœ… |
| Streamlit UI | `app.py` | âœ… |

## ğŸ“š Files Overview

**Core Files:**
- `app.py` - Main application (run this!)
- `requirements.txt` - All dependencies
- `README.md` - Project documentation

**Modules (in `modules/` folder):**
- `data_loader.py` - Handle CSV uploads
- `eda.py` - Automated analysis
- `issue_detector.py` - Find data problems
- `preprocessor.py` - Clean and prepare data
- `model_trainer.py` - Train 7 ML models
- `model_evaluator.py` - Compare models
- `report_generator.py` - Create reports

**Utilities:**
- `utils/helpers.py` - Helper functions

**Configuration:**
- `.streamlit/config.toml` - App settings

## ğŸ¯ Team Collaboration Tips

1. **Divide Work:**
   - Person 1: Testing, Screenshots, Documentation
   - Person 2: Demo Video, Report Writing
   - Person 3: Deployment, GitHub Setup

2. **Use GitHub:**
   - Create branches for testing
   - Use Pull Requests for major changes
   - Communicate through Issues

3. **Regular Testing:**
   - Test after any code changes
   - Use different datasets
   - Document any bugs

## âœ¨ Optional Enhancements

Want extra credit? Add:
- [ ] Cross-validation results
- [ ] Feature importance plots
- [ ] More visualization options
- [ ] Data export functionality
- [ ] Model persistence (save/load)
- [ ] Batch processing
- [ ] Email report feature

## ğŸ“ Need Help?

1. Check `PROJECT_GUIDE.md` for detailed instructions
2. Review error messages in terminal
3. Check Streamlit documentation: https://docs.streamlit.io
4. Search on Stack Overflow
5. Ask course instructor

## ğŸ‰ You're All Set!

Your AutoML system is complete and ready to use. All required features are implemented:

âœ… Full AutoML pipeline
âœ… 7 classification algorithms
âœ… Hyperparameter optimization
âœ… Interactive visualizations
âœ… Comprehensive reports
âœ… Production-ready code

**Next Steps:**
1. Run locally and test thoroughly
2. Record demo video
3. Write report with screenshots
4. Deploy to Streamlit Cloud
5. Submit all deliverables

**Good luck with your project! ğŸš€**

---

*For detailed explanations, see `PROJECT_GUIDE.md`*
*For project requirements, see `README.md`*
